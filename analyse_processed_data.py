"""
	Analyse the processed review data generated by process raw review data.py, to generate a file that contains features 
	ordered by thier product ids containing information about features present and a count of number of positive, negative,
	and neutral reviews corresponding to that review.
"""
from __future__ import division
from nltk.tokenize import RegexpTokenizer
from nltk import pos_tag
from nltk.corpus import stopwords
import sentiword_net_implementation as sni
from glob import glob
from re import compile, sub
from helper_functions import *


		# values to be initialised in constructor			
SWN_FILENAME = "SentiWordNet_3.0.0_20130122.txt"
cv = sni.SentiWordNetCorpusReader(SWN_FILENAME)
tokenizer = RegexpTokenizer(r"[\w\']+")
get_tokens = tokenizer.tokenize
stopwords_list = stopwords.words('english')
f = open("tokenized_noun_file.txt", "r")
final_file = open("output.txt", "w")
feature_list, feature_name = [], []
err_file = open("error_file.txt", "w")

negation_list = ['don\'t', 'not', 'never']
		# tasks to be done in the constructor itself!
		
subs_list = [compile("\'ve"), compile("\'d"), compile("\'s")]
replace_list = ["have", "would", "is"]


for i in f.readlines():
	feature = i.split(":")[0]
	feature_list.append(feature)
f.close()
# Start processing !!!
hf = HelperFunctions(feature_list)
tot_files = len(glob("list of products/*.txt"))
product = hf.get_product_names()
file_count = 0
percent = 0
print "Analysing reviews for sentiments. Go to \'Progress Report.txt\' for further details"



for filename in glob("list of products/*.txt"):
	progress_file = open("Progress Report.txt", "w")
	review_category = {}
	file_count += 1
	percent =  (file_count*100)//tot_files
	progress_file.write("Files Scanned: "+str(file_count)+"/"+str(tot_files) + "\n")
	progress_file.write("Progress: "+str(percent)+"%\n")
	progress_file.close()
	f = open(filename, "r")
	line = f.readline()
	reviews = []
	while line:
		reviews.append(line)
		line = f.readline()
	f.close()
	number_of_reviews = len(reviews)
	while len(reviews) > 0:
		review = reviews.pop(0)
		for i in range(3):
			review = subs_list[1].sub(replace_list[i], review)
		sentances = review.split(".")  						#splitting the review on the basis of fullstop. 
		feature_score = {}									#processing each sentance for it's feature
		feature_adverb_score = {}
		final_sentances = []
		for i in sentances:
			if not i:
				continue
			final_sentances.extend(hf.check_for_but(i))   	# split the sentances having but in them to 2 diff sentances
		for t in final_sentances:							# scan the final set of sentances to check for features
			reverse_polarity = False
			counter = False
			tokens = get_tokens(t)
			pos_tagged_tokens = pos_tag(tokens)
			tokens_without_stop_words = []
			prev_feature = feature_name
			feature_name = hf.get_all_features(pos_tagged_tokens)  #extract features from review

			for i in feature_name:
				if not review_category.has_key(i.strip(".,?/-").lower()):
					review_category[i.strip(".,?/-").lower()] = {'pos_review':0, 'neg_review': 0, 'neutral_review': 0}

			if (t.find("it") != -1 or t.find("It") != -1) and not feature_name:
				feature_name = prev_feature 
			for i in pos_tagged_tokens:    					#Remove the stop words!
				if (i[0].strip(".,?/-").lower() not in stopwords_list) or (i[0].strip(".,?/-").lower() == 'not'):
					tokens_without_stop_words.append(i)

			overall_pos_score, overall_neg_score = [], []
			overall_pos_score_adverb, overall_neg_score_adverb = [], []
			for i in tokens_without_stop_words:
				if i[1].find("JJ") != -1: 
					pos_score, neg_score = 0, 0
					synsets_of_adjective = cv.senti_synsets(i[0], 'a')
					if synsets_of_adjective:
						synsets_of_adjective = cv.senti_synsets(i[0])
					for synset in synsets_of_adjective:
						pos_score = pos_score + synset.pos_score/len(synsets_of_adjective)
						neg_score = neg_score + synset.neg_score/len(synsets_of_adjective)
					if pos_score > 0 or neg_score > 0:
						if reverse_polarity:
							overall_pos_score.append(neg_score)
							overall_neg_score.append(pos_score)
							reverse_polarity= False
						else:
							overall_pos_score.append(pos_score)
							overall_neg_score.append(neg_score)
				elif i[0] in negation_list:
					reverse_polarity = True 

			if len(overall_neg_score) == 0:
				overall_neg_score.append(0)
			if len(overall_pos_score) == 0:
				overall_pos_score.append(0)
			

			for name in feature_name:
				if feature_score.has_key(name):
					posi_score, negi_score = feature_score[name][0], feature_score[name][1]
					feature_score[name] = (posi_score + sum(overall_pos_score)/len(overall_pos_score), 
						negi_score + sum(overall_neg_score)/len(overall_neg_score))
				else:
					feature_score[name] = (sum(overall_pos_score)/len(overall_pos_score), 
										sum(overall_neg_score)/len(overall_neg_score))

		for name, score in feature_score.iteritems():
			try:
				if score[1] > 0.1 or score[0] > 0.1:
					if score[0] > score[1]:
							review_category[name]['pos_review'] += 1
					elif score[1] > score[0]:
						review_category[name]['neg_review'] += 1
					else:
						review_category[name]['neutral_review'] += 1
				else:
					review_category[name]['neutral_review'] += 1
			except KeyError:
				err_file.write(filename + "\t")
				err_file.write("name:  " +name+"\n"+repr(review_category) + "\n")
	final_file.write("Filename: "+ filename.split("\\")[1].split('.')[0])
	final_file.write("\nProduct:  "+ product[filename.split(".")[0].split('\\')[1]])
	final_file.write("\nNumber Of Reviews:   "+ repr(number_of_reviews))
	if len(review_category.keys()) == 0: 
		final_file.write("\nFeature List: No Features Found \n" )
	else:	
		final_file.write("\nFeature List:" +repr(review_category) + "\n")
	final_file.write("\n\n")
print ""
raw_input("Review Processing Complete. An output file with the name 'output.txt' has been created in the current directory. Press any key to continue...")
err_file.close()
final_file.close()
